{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train a decision tree\n",
    "# inputs: train_data = training data in array (samples x timepoints), train_label = training labels in array (samples x genes),\n",
    "# outputs: dtree = trained decision tree model \n",
    "def train_dtree(train_data,train_label):    \n",
    "    # create tree model\n",
    "    dtree = tree.DecisionTreeRegressor()\n",
    "    dtree.fit(train_data,train_label)\n",
    "    return dtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to test decision tree predictions and calculate RMSE\n",
    "# inputs: tree_model = trained decision tree model, data = numpy array of pSTAT data (samples x 2*timepoints; pSTAT3 then pSTAT1 concat.)\n",
    "# label = numpy array of gene expression labels corresponding to data (samples x genes flattened)\n",
    "# outputs: predict = numpy array of gene predictions (samples x genes flattened), rmse = root mean squared error\n",
    "def test_and_eval(tree_model,data,label):\n",
    "    # predict labels with DTree\n",
    "    predict = tree_model.predict(data)\n",
    "\n",
    "    # calculate RMSE \n",
    "    rmse = np.sqrt(np.sum((predict - label) ** 2,axis=0) / predict.shape[0])\n",
    "\n",
    "    return predict,rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data and labels (trajectories already normalized)\n",
    "train_norm_pSTAT3_data_df = pd.read_csv('Data/subset_training_data_pSTAT3.csv', header=None)\n",
    "train_label = np.asarray(pd.read_csv('Data/subset_training_label_pSTAT3.csv', header=None))\n",
    "\n",
    "# load testing data and labels (trajectories already normalized)\n",
    "test_norm_pSTAT3_data_df = pd.read_csv('Data/subset_testing_data_pSTAT3.csv', header=None)\n",
    "test_label = np.asarray(pd.read_csv('Data/subset_testing_label_pSTAT3.csv', header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeframes from paper (will be different than results from HMM_timeframe_ID.ipynb)\n",
    "# top row = frame start\n",
    "# bottom row = frame end\n",
    "pSTAT3_frames = np.array([[0,9,14,49,50,61],[8,13,48,49,60,90]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-fold CV for timeframe consolidation (training data only since it is optimization)\n",
    "# sample size for each partition \n",
    "n_cv = int(train_norm_pSTAT3_data_df.shape[0] / 10)\n",
    "cv_splits = np.arange(0,train_norm_pSTAT3_data_df.shape[0]+n_cv,n_cv)\n",
    "\n",
    "# test each timeframe individually \n",
    "for i in range(pSTAT3_frames.shape[1]):\n",
    "    print('Timeframe:',i+1)\n",
    "    \n",
    "    # variables to sum over CV runs\n",
    "    predict_sum = 0\n",
    "    rmse_sum = 0\n",
    "\n",
    "    for j in range(len(cv_splits)-1):\n",
    "        # split train and test set for CV\n",
    "        test_ind = np.arange(cv_splits[j],cv_splits[j+1])\n",
    "        \n",
    "        cv_test_data = np.asarray(train_norm_pSTAT3_data_df.iloc[test_ind,pSTAT3_frames[0,i]:pSTAT3_frames[1,i]+1])\n",
    "        cv_test_label = train_label[test_ind,:]\n",
    "        \n",
    "        cv_train_data = np.delete(np.asarray(train_norm_pSTAT3_data_df.iloc[:,pSTAT3_frames[0,i]:pSTAT3_frames[1,i]+1]),test_ind,axis=0)\n",
    "        cv_train_label = np.delete(train_label,test_ind,axis=0)\n",
    "\n",
    "        # train and test DTree\n",
    "        test_dtree = train_dtree(cv_train_data,cv_train_label)\n",
    "        test_predict,test_rmse = test_and_eval(test_dtree,cv_test_data,cv_test_label)\n",
    "\n",
    "        # add to storage variables\n",
    "        predict_sum+=test_predict\n",
    "        rmse_sum+=test_rmse\n",
    "\n",
    "    # average over CV runs\n",
    "    avg_cv_predict = predict_sum / (len(cv_splits)-1)\n",
    "    avg_cv_rmse =  rmse_sum / (len(cv_splits)-1)\n",
    "\n",
    "    # uncomment to save timeframe predictions\n",
    "    # np.savetxt('avg_cv_predict' + '_frame' + str(i+1) + '.csv', avg_cv_predict, delimiter=',')\n",
    "    # np.savetxt('avg_cv_rmse' + '_frame' + str(i+1) + '.txt',avg_cv_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early predictions using timeframes from paper\n",
    "early_test_dtree = train_dtree(np.asarray(train_norm_pSTAT3_data_df.iloc[:,0:14]),train_label)\n",
    "early_test_predict,early_test_rmse = test_and_eval(early_test_dtree,np.asarray(test_norm_pSTAT3_data_df.iloc[:,0:14]),test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# late predictions using timeframes from paper\n",
    "late_test_dtree = train_dtree(np.asarray(train_norm_pSTAT3_data_df.iloc[:,49:]),train_label)\n",
    "late_test_predict,late_test_rmse = test_and_eval(late_test_dtree,np.asarray(test_norm_pSTAT3_data_df.iloc[:,49:]),test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
